<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>OpenAI Embeddings Visualizer</title>
  <style>    body {
      font-family: Arial, sans-serif;
      max-width: 1200px;
      margin: 0 auto;
      padding: 20px;
      background-color: #f5f5f5;
    }
    
    .container {
      background: white;
      padding: 30px;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    h1 {
      color: #333;
      text-align: center;
      margin-bottom: 30px;
    }
    
    .input-section {
      margin-bottom: 20px;
    }
    
    label {
      display: block;
      margin-bottom: 8px;
      font-weight: bold;
      color: #555;
    }
      /* Textarea styling for all sections */
    .input-section textarea {
      width: 100%;
      max-width: 250px;
      height: 150px;
      padding: 10px;
      border: 2px solid #ddd;
      border-radius: 5px;
      font-size: 14px;
      resize: vertical;
      font-family: inherit;
    }/* Embed and Settings buttons styling for all sections */
    #embedButtonProto,
    #embedButtonTest1,
    #embedButtonTest2 {
      background-color: #4CAF50;
      color: white;
    }
    #embedButtonProto:hover,
    #embedButtonTest1:hover,
    #embedButtonTest2:hover {
      background-color: #45a049;
    }
    #embedButtonProto:disabled,
    #embedButtonTest1:disabled,
    #embedButtonTest2:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    #settingsButtonGlobal {
      background-color: #2196F3;
      color: white;
      padding: 10px 15px;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      font-size: 14px;
      margin-bottom: 20px;
    }
    #settingsButtonGlobal:hover {
      background-color: #1976D2;
    }    /* Embedding canvas styling for all sections */
    #embeddingCanvasProto,
    #embeddingCanvasTest1,
    #embeddingCanvasTest2 {
      border: 2px solid #ddd;
      border-radius: 5px;
      margin: 20px 0;
      background: white;
      width: 160px;
      height: 240px;
      image-rendering: pixelated;
      image-rendering: -moz-crisp-edges;
      image-rendering: crisp-edges;
      cursor: pointer;
      transition: border-color 0.3s;
    }
    #embeddingCanvasProto:hover,
    #embeddingCanvasTest1:hover,
    #embeddingCanvasTest2:hover {
      border-color: #4CAF50;
    }
    
    .status {
      margin: 10px 0;
      padding: 10px;
      border-radius: 5px;
      display: none;
    }
    
    .status.success {
      background-color: #d4edda;
      color: #155724;
      border: 1px solid #c3e6cb;
    }
    
    .status.error {
      background-color: #f8d7da;
      color: #721c24;
      border: 1px solid #f5c6cb;
    }
    
    .status.loading {
      background-color: #cce7ff;
      color: #0056b3;
      border: 1px solid #99d6ff;
    }
    
    /* Modal Styles */
    .modal {
      display: none;
      position: fixed;
      z-index: 1000;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0,0,0,0.5);
    }    /* Four-column layout */
    .columns {
      display: flex;
      gap: 15px;
    }
    .col {
      flex: 1;
      min-width: 0; /* Allows flex items to shrink below their content size */
    }

    .modal-content {
      background-color: white;
      margin: 15% auto;
      padding: 30px;
      border-radius: 10px;
      width: 400px;
      max-width: 90%;
      box-shadow: 0 4px 20px rgba(0,0,0,0.3);
    }
    
    .modal-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 20px;
    }
    
    .close {
      color: #aaa;
      font-size: 28px;
      font-weight: bold;
      cursor: pointer;
      line-height: 1;
    }
    
    .close:hover {
      color: #000;
    }
    
    .modal input {
      width: 100%;
      padding: 10px;
      border: 2px solid #ddd;
      border-radius: 5px;
      font-size: 14px;
      margin-bottom: 15px;
      box-sizing: border-box;
    }
    
    .modal-buttons {
      display: flex;
      gap: 10px;
      justify-content: flex-end;
    }
    
    .info-text {
      font-size: 12px;
      color: #666;
      margin-bottom: 15px;
    }
    
    .embedding-info {
      font-size: 14px;
      color: #666;
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>OpenAI Embeddings Visualizer</h1>
    
    <div class="columns">
      <!-- Basis Transform Column -->
      <div class="col" id="basis-transform">
        <h2>Basis Transform</h2>
        <div class="button-section">
          <button id="settingsButtonGlobal">Settings</button>
        </div>
        <div class="input-section">
          <label for="basisImageUpload">Upload an image (32×48 grayscale basis):</label>
          <input type="file" id="basisImageUpload" accept="image/*">
        </div>
        <div class="visualization-section">
          <h3>Basis Grayscale (32×48 pixels)</h3>
          <canvas id="basisCanvas" width="160" height="240" style="border:2px solid #ddd; border-radius:5px; background:white; image-rendering:pixelated; width:160px; height:240px;"></canvas>
          <div class="embedding-info" id="basisInfo">
            The uploaded image will be resized and converted to a 32×48 grayscale vector.<br>
            This vector will be used as a basis for future transforms.
          </div>
        </div>
      </div>
      <div class="col" id="prototype">
        <h2>Prototype</h2>
        <div class="input-section">
          <label for="textInputProto">Enter text to embed:</label>
          <textarea id="textInputProto" placeholder="Type your text here..."></textarea>
        </div>
        <div class="button-section">
          <button id="embedButtonProto">Embed</button>
        </div>
        <div id="statusProto" class="status"></div>
        <div class="visualization-section">
          <h3>Embedding Visualization (32×48 pixels)</h3>
          <canvas id="embeddingCanvasProto" width="32" height="48"></canvas>
          <div class="embedding-info" id="embeddingInfoProto">
            Each pixel represents one dimension of the embedding vector.<br>
            Brightness corresponds to the value (-1 to 1 range).<br>
            <strong>Click the image to copy CSV data to clipboard.</strong>
          </div>
        </div>
      </div>      <div class="col" id="test1">
        <h2>Test 1</h2>
        <div class="input-section">
          <label for="textInputTest1">Enter text to embed:</label>
          <textarea id="textInputTest1" placeholder="Type your text here..."></textarea>
        </div>
        <div class="button-section">
          <button id="embedButtonTest1">Embed</button>
        </div>
        <div id="statusTest1" class="status"></div>
        <div class="visualization-section">
          <h3>Embedding Visualization (32×48 pixels)</h3>
          <canvas id="embeddingCanvasTest1" width="32" height="48"></canvas>
          <div class="embedding-info" id="embeddingInfoTest1">
            Each pixel represents one dimension of the embedding vector.<br>
            Brightness corresponds to the value (-1 to 1 range).<br>
            <strong>Click the image to copy CSV data to clipboard.</strong>
          </div>
        </div>
      </div>
      <div class="col" id="test2">
        <h2>Test 2</h2>
        <div class="input-section">
          <label for="textInputTest2">Enter text to embed:</label>
          <textarea id="textInputTest2" placeholder="Type your text here..."></textarea>
        </div>
        <div class="button-section">
          <button id="embedButtonTest2">Embed</button>
        </div>
        <div id="statusTest2" class="status"></div>
        <div class="visualization-section">
          <h3>Embedding Visualization (32×48 pixels)</h3>
          <canvas id="embeddingCanvasTest2" width="32" height="48"></canvas>
          <div class="embedding-info" id="embeddingInfoTest2">
            Each pixel represents one dimension of the embedding vector.<br>
            Brightness corresponds to the value (-1 to 1 range).<br>
            <strong>Click the image to copy CSV data to clipboard.</strong>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Settings Modal -->
  <div id="settingsModal" class="modal">
    <div class="modal-content">
      <div class="modal-header">
        <h3>Settings</h3>
        <span class="close">&times;</span>
      </div>
      <div class="info-text">
        Enter your OpenAI API key. It will be stored locally in your browser.
      </div>
      <input type="password" id="apiKeyInput" placeholder="sk-..." />
      <div class="modal-buttons">
        <button id="saveButton">Save</button>
        <button id="cancelButton">Cancel</button>
      </div>
    </div>
  </div>

  <script>
    // DOM Elements
    // Prototype section elements
    const textInputProto = document.getElementById('textInputProto');
    const embedButtonProto = document.getElementById('embedButtonProto');
    const statusProto = document.getElementById('statusProto');
    const canvasProto = document.getElementById('embeddingCanvasProto');
    const ctxProto = canvasProto.getContext('2d');    // Test 1 section elements
    const textInputTest1 = document.getElementById('textInputTest1');
    const embedButtonTest1 = document.getElementById('embedButtonTest1');
    const statusTest1 = document.getElementById('statusTest1');
    const canvasTest1 = document.getElementById('embeddingCanvasTest1');
    const ctxTest1 = canvasTest1.getContext('2d');

    // Test 2 section elements
    const textInputTest2 = document.getElementById('textInputTest2');
    const embedButtonTest2 = document.getElementById('embedButtonTest2');
    const statusTest2 = document.getElementById('statusTest2');
    const canvasTest2 = document.getElementById('embeddingCanvasTest2');
    const ctxTest2 = canvasTest2.getContext('2d');

    // Basis Transform elements
    const basisImageUpload = document.getElementById('basisImageUpload');
    const basisCanvas = document.getElementById('basisCanvas');
    const ctxBasis = basisCanvas.getContext('2d');
    const basisInfo = document.getElementById('basisInfo');
    const settingsButtonGlobal = document.getElementById('settingsButtonGlobal');

    const modal = document.getElementById('settingsModal');
    const apiKeyInput = document.getElementById('apiKeyInput');
    const saveButton = document.getElementById('saveButton');
    const cancelButton = document.getElementById('cancelButton');
    const closeButton = document.querySelector('.close');    // Store the current embedding data
    let currentEmbedding = null;
    let currentNormalizedValues = null;
    let currentEmbeddingTest1 = null;
    let currentNormalizedValuesTest1 = null;
    let currentEmbeddingTest2 = null;
    let currentNormalizedValuesTest2 = null;    // Initialize canvases
    ctxProto.fillStyle = '#f0f0f0';
    ctxProto.fillRect(0, 0, 32, 48);
    ctxTest1.fillStyle = '#f0f0f0';
    ctxTest1.fillRect(0, 0, 32, 48);
    ctxTest2.fillStyle = '#f0f0f0';
    ctxTest2.fillRect(0, 0, 32, 48);

    // Modal functionality
    settingsButtonGlobal.addEventListener('click', () => {
      const existingKey = localStorage.getItem('OPENAI_API_KEY');
      if (existingKey) {
        apiKeyInput.value = existingKey;
      }
      modal.style.display = 'block';
    });

    closeButton.addEventListener('click', () => {
      modal.style.display = 'none';
    });

    cancelButton.addEventListener('click', () => {
      modal.style.display = 'none';
    });

    saveButton.addEventListener('click', () => {
      const apiKey = apiKeyInput.value.trim();
      if (apiKey) {
        localStorage.setItem('OPENAI_API_KEY', apiKey);
        showStatus(statusProto, 'API key saved successfully!', 'success');
      } else {
        showStatus(statusProto, 'Please enter a valid API key', 'error');
        return;
      }
      modal.style.display = 'none';
    });

    window.addEventListener('click', (event) => {
      if (event.target === modal) {
        modal.style.display = 'none';
      }
    });

    // Status display function for a given section
    function showStatus(statusEl, message, type) {
      statusEl.textContent = message;
      statusEl.className = `status ${type}`;
      statusEl.style.display = 'block';
      if (type !== 'loading') {
        setTimeout(() => {
          statusEl.style.display = 'none';
        }, 3000);
      }
    }

    // Embedding functions
    async function getEmbedding(inputText) {
      const apiKey = localStorage.getItem('OPENAI_API_KEY');
      if (!apiKey) {
        throw new Error('OpenAI API key missing in localStorage. Please set it in Settings.');
      }

      const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: 'text-embedding-ada-002',
          input: inputText,
        }),
      });

      const result = await response.json();
      if (result.error) {
        throw new Error(`Embedding API error: ${result.error.message}`);
      }
      return result.data[0].embedding;
    }

    function mapValueToNormalized(value) {
      const clamped = Math.max(-1, Math.min(1, value));
      
      // More aggressive exponential normalization for maximum mid-range contrast
      // Using a smaller exponent (0.3) for even more dramatic spread
      let normalized;
      if (clamped >= 0) {
        // For positive values: apply more aggressive exponential curve
        const exp = Math.pow(clamped, 0.3); // Cube root for maximum expansion
        normalized = 0.5 + (exp * 0.5); // Map to [0.5, 1.0]
      } else {
        // For negative values: apply more aggressive exponential curve symmetrically
        const exp = Math.pow(Math.abs(clamped), 0.3); // Cube root for maximum expansion
        normalized = 0.5 - (exp * 0.5); // Map to [0.0, 0.5]
      }
      
      return normalized;
    }

    function mapValueToGrayscaleRGB(value) {
      const normalized = mapValueToNormalized(value);
      
      // Convert to 0-255 range
      const grayscale = Math.round(normalized * 255);
      return [grayscale, grayscale, grayscale];
    }

    function renderEmbeddingToCanvas(embedding, width, height) {
      canvasProto.width = width;
      canvasProto.height = height;
      const imageData = ctxProto.createImageData(width, height);
      const data = imageData.data;

      // Calculate and store normalized values
      const normalizedValues = [];

      // Apply basis reordering if mapping exists
      let embeddingToRender = embedding;
      let transformDescription = "Vector displayed in native order from embedding algorithm.";
      
      if (basisOrderMapping && embedding.length === basisOrderMapping.length) {
        const result = reorderPrototypeByBasis(embedding, basisOrderMapping);
        embeddingToRender = result.reordered;
        prototypeReorderingIndices = result.indices; // Store for test to use
        transformDescription = "Vector reordered to recreate basis image structure. Lightest embedding values mapped to brightest basis pixels.";
          // Retrigger test remapping if test embeddings exist
        if (currentEmbeddingTest1) {
          renderEmbeddingToCanvasTest1(currentEmbeddingTest1, 32, 48);
        }
        if (currentEmbeddingTest2) {
          renderEmbeddingToCanvasTest2(currentEmbeddingTest2, 32, 48);
        }
      }

      for (let i = 0; i < embeddingToRender.length && i < width * height; i++) {
        const normalizedValue = mapValueToNormalized(embeddingToRender[i]);
        normalizedValues.push(normalizedValue);
        
        const [r, g, b] = mapValueToGrayscaleRGB(embeddingToRender[i]);
        const pixelIndex = i * 4;
        data[pixelIndex] = r;     // Red
        data[pixelIndex + 1] = g; // Green
        data[pixelIndex + 2] = b; // Blue
        data[pixelIndex + 3] = 255; // Alpha (fully opaque)
      }

      // Store normalized values in page data model
      currentNormalizedValues = normalizedValues;

      ctxProto.putImageData(imageData, 0, 0);
      
      // Update transformation description
      document.getElementById('embeddingInfoProto').innerHTML = `
        Each pixel represents one dimension of the embedding vector.<br>
        Values are exponentially normalized (cube root) from the raw -1 to 1 range to enhance visual contrast.<br>
        <strong>Click the image to copy CSV data to clipboard.</strong><br>
        <em>Transform: ${transformDescription}</em>
      `;
    }    // Test 1 section rendering function
    function renderEmbeddingToCanvasTest1(embedding, width, height) {
      canvasTest1.width = width;
      canvasTest1.height = height;
      const imageData = ctxTest1.createImageData(width, height);
      const data = imageData.data;
      const normalizedValues = [];

      // Apply the EXACT SAME reordering indices as the prototype
      let embeddingToRender = embedding;
      let transformDescription = "Vector displayed in native order from embedding algorithm.";
      
      if (prototypeReorderingIndices && embedding.length === prototypeReorderingIndices.length) {
        embeddingToRender = reorderTestUsingPrototypeIndices(embedding, prototypeReorderingIndices);
        transformDescription = "Vector reordered using identical mapping as prototype. Shows semantic differences in basis image structure.";
      }

      for (let i = 0; i < embeddingToRender.length && i < width * height; i++) {
        const normalizedValue = mapValueToNormalized(embeddingToRender[i]);
        normalizedValues.push(normalizedValue);
        const [r, g, b] = mapValueToGrayscaleRGB(embeddingToRender[i]);
        const idx = i * 4;
        data[idx] = r;
        data[idx + 1] = g;
        data[idx + 2] = b;
        data[idx + 3] = 255;
      }
      currentNormalizedValuesTest1 = normalizedValues;
      ctxTest1.putImageData(imageData, 0, 0);
      
      // Update transformation description
      document.getElementById('embeddingInfoTest1').innerHTML = `
        Each pixel represents one dimension of the embedding vector.<br>
        Values are exponentially normalized (cube root) from the raw -1 to 1 range to enhance visual contrast.<br>
        <strong>Click the image to copy CSV data to clipboard.</strong><br>
        <em>Transform: ${transformDescription}</em>
      `;
    }

    // Test 2 section rendering function
    function renderEmbeddingToCanvasTest2(embedding, width, height) {
      canvasTest2.width = width;
      canvasTest2.height = height;
      const imageData = ctxTest2.createImageData(width, height);
      const data = imageData.data;
      const normalizedValues = [];

      // Apply the EXACT SAME reordering indices as the prototype
      let embeddingToRender = embedding;
      let transformDescription = "Vector displayed in native order from embedding algorithm.";
      
      if (prototypeReorderingIndices && embedding.length === prototypeReorderingIndices.length) {
        embeddingToRender = reorderTestUsingPrototypeIndices(embedding, prototypeReorderingIndices);
        transformDescription = "Vector reordered using identical mapping as prototype. Shows semantic differences in basis image structure.";
      }

      for (let i = 0; i < embeddingToRender.length && i < width * height; i++) {
        const normalizedValue = mapValueToNormalized(embeddingToRender[i]);
        normalizedValues.push(normalizedValue);
        const [r, g, b] = mapValueToGrayscaleRGB(embeddingToRender[i]);
        const idx = i * 4;
        data[idx] = r;
        data[idx + 1] = g;
        data[idx + 2] = b;
        data[idx + 3] = 255;
      }
      currentNormalizedValuesTest2 = normalizedValues;
      ctxTest2.putImageData(imageData, 0, 0);
      
      // Update transformation description
      document.getElementById('embeddingInfoTest2').innerHTML = `
        Each pixel represents one dimension of the embedding vector.<br>
        Values are exponentially normalized (cube root) from the raw -1 to 1 range to enhance visual contrast.<br>
        <strong>Click the image to copy CSV data to clipboard.</strong><br>
        <em>Transform: ${transformDescription}</em>
      `;
    }

    // CSV export functionality
    function embeddingToCSV(embedding) {
      const width = 32;
      const height = 48;
      const rows = [];
      
      for (let row = 0; row < height; row++) {
        const rowData = [];
        for (let col = 0; col < width; col++) {
          const index = row * width + col;
          if (index < embedding.length) {
            rowData.push(embedding[index].toFixed(6));
          } else {
            rowData.push('0.000000');
          }
        }
        rows.push(rowData.join(','));
      }
      
      return rows.join('\n');
    }

    async function copyToClipboard(text) {
      try {
        await navigator.clipboard.writeText(text);
        return true;
      } catch (err) {
        // Fallback for older browsers
        const textArea = document.createElement('textarea');
        textArea.value = text;
        textArea.style.position = 'fixed';
        textArea.style.opacity = '0';
        document.body.appendChild(textArea);
        textArea.focus();
        textArea.select();
        
        try {
          const successful = document.execCommand('copy');
          document.body.removeChild(textArea);
          return successful;
        } catch (err) {
          document.body.removeChild(textArea);
          return false;
        }
      }
    }    // Event handlers for test 1 section
    embedButtonTest1.addEventListener('click', async () => {
      const text = textInputTest1.value.trim();
      if (!text) return showStatus(statusTest1, 'Please enter some text to embed', 'error');
      embedButtonTest1.disabled = true;
      showStatus(statusTest1, 'Generating embedding...', 'loading');
      try {
        const embedding = await getEmbedding(text);
        renderEmbeddingToCanvasTest1(embedding, 32, 48);
        currentEmbeddingTest1 = embedding;
        showStatus(statusTest1, `Embedding generated successfully! (${embedding.length} dimensions)`, 'success');
      } catch (error) {
        showStatus(statusTest1, error.message, 'error');
        console.error('Embedding error:', error);
      } finally {
        embedButtonTest1.disabled = false;
      }
    });
    
    canvasTest1.addEventListener('click', async () => {
      if (!currentEmbeddingTest1) return showStatus(statusTest1, 'No embedding data available. Please generate an embedding first.', 'error');
      const csvData = embeddingToCSV(currentEmbeddingTest1);
      const success = await copyToClipboard(csvData);
      showStatus(statusTest1, success ? 'CSV data copied to clipboard!' : 'Failed to copy to clipboard. Please try again.', success ? 'success' : 'error');
    });

    // Event handlers for test 2 section
    embedButtonTest2.addEventListener('click', async () => {
      const text = textInputTest2.value.trim();
      if (!text) return showStatus(statusTest2, 'Please enter some text to embed', 'error');
      embedButtonTest2.disabled = true;
      showStatus(statusTest2, 'Generating embedding...', 'loading');
      try {
        const embedding = await getEmbedding(text);
        renderEmbeddingToCanvasTest2(embedding, 32, 48);
        currentEmbeddingTest2 = embedding;
        showStatus(statusTest2, `Embedding generated successfully! (${embedding.length} dimensions)`, 'success');
      } catch (error) {
        showStatus(statusTest2, error.message, 'error');
        console.error('Embedding error:', error);
      } finally {
        embedButtonTest2.disabled = false;
      }
    });
    
    canvasTest2.addEventListener('click', async () => {
      if (!currentEmbeddingTest2) return showStatus(statusTest2, 'No embedding data available. Please generate an embedding first.', 'error');
      const csvData = embeddingToCSV(currentEmbeddingTest2);
      const success = await copyToClipboard(csvData);
      showStatus(statusTest2, success ? 'CSV data copied to clipboard!' : 'Failed to copy to clipboard. Please try again.', success ? 'success' : 'error');
    });

    // Canvas click handler for CSV export (prototype)
    canvasProto.addEventListener('click', async () => {
      if (!currentEmbedding) return showStatus(statusProto, 'No embedding data available. Please generate an embedding first.', 'error');

      const csvData = embeddingToCSV(currentEmbedding);
      const success = await copyToClipboard(csvData);
      showStatus(statusProto, success ? 'CSV data copied to clipboard!' : 'Failed to copy to clipboard. Please try again.', success ? 'success' : 'error');
    });

    // Embed button functionality (prototype)
    embedButtonProto.addEventListener('click', async () => {
      const text = textInputProto.value.trim();
      if (!text) return showStatus(statusProto, 'Please enter some text to embed', 'error');

      embedButtonProto.disabled = true;
      showStatus(statusProto, 'Generating embedding...', 'loading');

      try {
        const embedding = await getEmbedding(text);
        renderEmbeddingToCanvas(embedding, 32, 48);
        currentEmbedding = embedding;
        showStatus(statusProto, `Embedding generated successfully! (${embedding.length} dimensions)`, 'success');
      } catch (error) {
        showStatus(statusProto, error.message, 'error');
        console.error('Embedding error:', error);
      } finally {
        embedButtonProto.disabled = false;
      }
    });

    // Basis Transform functionality
    // Use the same logic as image_test.html for 32x48 grayscale vector extraction
    let basisGrayscaleVector = [];
    let basisNormalizedGrayscaleVector = [];
    let basisOrderMapping = null; // Stores the reordering indices
    let prototypeReorderingIndices = null; // Stores the exact reordering used for prototype

    // Function to create basis ordering mapping
    function createBasisOrderMapping(basisVector) {
      // Create array of {value, originalIndex} pairs
      const indexedValues = basisVector.map((value, index) => ({
        value: value,
        originalIndex: index
      }));
      
      // Sort by value (lightest to darkest)
      indexedValues.sort((a, b) => a.value - b.value);
      
      // Create mapping: original position -> new position in sorted order
      const mapping = new Array(basisVector.length);
      indexedValues.forEach((item, newIndex) => {
        mapping[item.originalIndex] = newIndex;
      });
      
      return mapping;
    }

    // Function to reorder prototype vector based on basis mapping
    function reorderPrototypeByBasis(vector, mapping) {
      if (!mapping || mapping.length !== vector.length) return { reordered: vector, indices: null };
      
      // Create array of {value, originalIndex} pairs for the embedding vector
      const indexedEmbedding = vector.map((value, index) => ({
        value: value,
        originalIndex: index
      }));
      
      // Sort embedding values from smallest to largest (lightest to darkest)
      indexedEmbedding.sort((a, b) => a.value - b.value);
      
      // Create the reordered vector and store the indices used
      const reordered = new Array(vector.length);
      const usedIndices = new Array(vector.length);
      
      // Map sorted embedding values to basis positions
      // The brightest basis pixels get the lightest embedding values
      for (let i = 0; i < vector.length; i++) {
        // Find where this basis pixel ranks in brightness (0 = darkest basis pixel)
        const basisRank = mapping[i];
        // Get the embedding value that should go here (lightest embedding values go to brightest basis pixels)
        const embeddingItem = indexedEmbedding[basisRank];
        reordered[i] = embeddingItem.value;
        usedIndices[i] = embeddingItem.originalIndex; // Store which original index was used
      }
      
      return { reordered, indices: usedIndices };
    }

    // Function to reorder test vector using the same indices as prototype
    function reorderTestUsingPrototypeIndices(vector, indices) {
      if (!indices || indices.length !== vector.length) return vector;
      
      const reordered = new Array(vector.length);
      for (let i = 0; i < vector.length; i++) {
        reordered[i] = vector[indices[i]];
      }
      
      return reordered;
    }

    basisImageUpload.addEventListener('change', async (event) => {
      const file = event.target.files[0];
      if (!file) return;

      // 1) Load image
      const img = new Image();
      img.src = await new Promise(res => {
        const fr = new FileReader();
        fr.onload = () => res(fr.result);
        fr.readAsDataURL(file);
      });

      img.onload = () => {
        // 2) Draw into offscreen 32×48 canvas
        const OFF_WIDTH = 32;
        const OFF_HEIGHT = 48;
        const off = document.createElement('canvas');
        off.width = OFF_WIDTH;
        off.height = OFF_HEIGHT;
        const offCtx = off.getContext('2d');
        offCtx.imageSmoothingEnabled = true;
        offCtx.drawImage(img, 0, 0, off.width, off.height);

        // 3) Grab the pixels, compute grayscale & vectors, AND overwrite to true gray
        const imgData = offCtx.getImageData(0, 0, off.width, off.height);
        const d = imgData.data;
        basisGrayscaleVector = [];
        basisNormalizedGrayscaleVector = [];

        for (let i = 0; i < d.length; i += 4) {
          // luminosity
          const lum = 0.299 * d[i] + 0.587 * d[i+1] + 0.114 * d[i+2];
          const norm = lum / 255;
          const grey = Math.round(norm * 255);

          basisNormalizedGrayscaleVector.push(norm);
          basisGrayscaleVector.push(grey);

          // overwrite pixel to gray
          d[i] = d[i+1] = d[i+2] = grey;
          d[i+3] = 255;
        }
        offCtx.putImageData(imgData, 0, 0);

        // 4) Create the basis ordering mapping
        basisOrderMapping = createBasisOrderMapping(basisNormalizedGrayscaleVector);

        // 5) Resize & draw the grayscaled offscreen full-canvas (5x scale)
        ctxBasis.imageSmoothingEnabled = false;
        ctxBasis.clearRect(0, 0, basisCanvas.width, basisCanvas.height);
        ctxBasis.drawImage(
          off,
          0, 0, off.width, off.height,
          0, 0, basisCanvas.width, basisCanvas.height
        );        // 6) Re-render existing embeddings with basis ordering if they exist
        if (currentEmbedding && currentNormalizedValues) {
          renderEmbeddingToCanvas(currentEmbedding, 32, 48);
        }
        if (currentEmbeddingTest1 && currentNormalizedValuesTest1) {
          renderEmbeddingToCanvasTest1(currentEmbeddingTest1, 32, 48);
        }
        if (currentEmbeddingTest2 && currentNormalizedValuesTest2) {
          renderEmbeddingToCanvasTest2(currentEmbeddingTest2, 32, 48);
        }

        // 7) Expose for downstream embedding code
        window.basisGrayscaleVector = basisGrayscaleVector;
        window.basisNormalizedGrayscaleVector = basisNormalizedGrayscaleVector;
        window.basisOrderMapping = basisOrderMapping;

        console.log('basisGrayscaleVector:', basisGrayscaleVector);
        console.log('basisNormalizedGrayscaleVector:', basisNormalizedGrayscaleVector);
        console.log('basisOrderMapping:', basisOrderMapping);
      };
    });

    // Check if API key exists on load
    window.addEventListener('load', () => {
      const apiKey = localStorage.getItem('OPENAI_API_KEY');
      if (!apiKey) showStatus(statusProto, 'Please set your OpenAI API key in Settings to get started', 'error');
    });
  </script>
</body>
</html>